{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\"> Data Preparation </span>\n",
    "\n",
    "This notebook describes how we construct datasets that we might use in this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing external libraries\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# import internal libraries\n",
    "os.chdir('../')\n",
    "import lib.text_pre_processing as preprocess\n",
    "\n",
    "sns.set(rc={\"figure.dpi\":300, 'savefig.dpi':300})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\"> XIV legislature</span>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the questions and actors info (deputies) of the 14th legislature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the json files \n",
    "PATH_JSON_XIV_QUESTIONS = \"data/legislature_XIV/questions.json\"\n",
    "PATH_JSON_XIV_INFO_DEPUTES = \"data/legislature_XIV/info_deputes_senateurs_ministres.json\"\n",
    "\n",
    "\n",
    "with open(PATH_JSON_XIV_QUESTIONS, 'r') as fjson_Q:\n",
    "  data_questions = json.loads(fjson_Q.read())\n",
    "\n",
    "with open(PATH_JSON_XIV_INFO_DEPUTES, 'r') as fjson_info:\n",
    "  data_info_dep = json.loads(fjson_info.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve list of questions and actors\n",
    "list_questions = data_questions['questionsEcrites']['question']\n",
    "list_actors = data_info_dep['export']['acteurs']['acteur']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating datasets\n",
    "\n",
    "We will need to create 2 datasets:\n",
    "* `df_actors`: including deputies (askers) information:\n",
    "  * author_id: id of the deputy\n",
    "  * civ:  M. or Mme\n",
    "  * firstname\n",
    "  * lastname\n",
    "  * birth_date: date of birth\n",
    "  * birth_dep: department of birth\n",
    "  * birth_country: country of birth\n",
    "  \n",
    "  <br>\n",
    "* `df_questions`: questions information:\n",
    "  * q_text: text of the question\n",
    "  * author_id: id of the author\n",
    "  * author_org: organisation of the author\n",
    "  * section: question section\n",
    "  * analysis_head: head of the question\n",
    "  * answer_min: minister answering the question\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Actors (deputies) dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare dictionary of actors for the dataframe\n",
    "info_actors = {'author_id':[], 'civ':[], 'firstname':[], 'lastname':[], 'birth_date':[], 'birth_dep': [], 'birth_country':[]}\n",
    "for i, actor in enumerate(list_actors):\n",
    "    author_id = actor['uid']['#text']\n",
    "    civ = actor['etatCivil']['ident']['civ']\n",
    "    firstname = actor['etatCivil']['ident']['prenom']\n",
    "    lastname = actor['etatCivil']['ident']['nom']\n",
    "    birth_date = actor['etatCivil']['infoNaissance']['dateNais']\n",
    "    birth_dep = actor['etatCivil']['infoNaissance']['depNais']\n",
    "    birth_country = actor['etatCivil']['infoNaissance']['paysNais']\n",
    "\n",
    "    info_actors['author_id'].append(author_id)\n",
    "    info_actors['civ'].append(civ)\n",
    "    info_actors['firstname'].append(firstname)\n",
    "    info_actors['lastname'].append(lastname)\n",
    "    info_actors['birth_date'].append(birth_date)\n",
    "    info_actors['birth_dep'].append(birth_dep)\n",
    "    info_actors['birth_country'].append(birth_country)\n",
    "\n",
    "# creating dataframes\n",
    "df_actors = pd.DataFrame(info_actors)\n",
    "\n",
    "# ensure there are no duplicate instances\n",
    "len(df_actors) == df_actors['author_id'].nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Questions dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions :  104142\n"
     ]
    }
   ],
   "source": [
    "# prepare dictionary of questions for the dataframe\n",
    "info_questions = {'q_text':[], 'author_id':[], 'author_org':[], 'author_org_abrev':[], 'section':[], 'analysis_head':[], 'answer_min':[]}\n",
    "for i, question in enumerate(list_questions):\n",
    "    try: \n",
    "        q_text = question['textesQuestion']['texteQuestion']['texte']\n",
    "    except:\n",
    "        q_text = question['textesQuestion']['texteQuestion'][0]['texte']\n",
    "        \n",
    "    if type(q_text) == str:\n",
    "        author_id = question['auteur']['identite']['acteurRef']\n",
    "        author_org = question['auteur']['groupe']['developpe']\n",
    "        author_org_abrev = question['auteur']['groupe']['abrege']\n",
    "        section = question['indexationAN']['rubrique']\n",
    "        analysis_head = question['indexationAN']['teteAnalyse']\n",
    "        answer_min = question['minInt']['abrege']\n",
    "\n",
    "        info_questions['q_text'].append(q_text)\n",
    "        info_questions['author_id'].append(author_id)\n",
    "        info_questions['author_org'].append(author_org)\n",
    "        info_questions['author_org_abrev'].append(author_org_abrev)\n",
    "        info_questions['section'].append(section)\n",
    "        info_questions['analysis_head'].append(analysis_head)\n",
    "        info_questions['answer_min'].append(answer_min)\n",
    "\n",
    "# creating dataframes\n",
    "df_questions = pd.DataFrame(info_questions)\n",
    "\n",
    "print('Number of questions : ', len(df_questions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing questions text\n",
    "\n",
    "We will only be interested on learning embeddings of words in the questions asked by deptuies. For this purpose, we will first prepape the data for the embedding models. \n",
    "\n",
    "As a first step, we clean the text by removing:\n",
    "* html tags\n",
    "* removing some anomalies: \"xa0\" and \"\\\\'\"\n",
    "* url links\n",
    "* put in lowercase\n",
    "* put space between words and punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = list(df_questions['q_text'])\n",
    "\n",
    "# remove html tags using BeautifulSoup\n",
    "html_q = preprocess.remove_tags(text_list)\n",
    "\n",
    "# removing some anomalies: \\xa0, apostrophes (replace \\' by '), url\n",
    "cln_corpus = preprocess.remove_anomalies(html_q)\n",
    "\n",
    "# inserting the cleaned text into the dataframe\n",
    "df_questions['q_text'] = cln_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_org</th>\n",
       "      <th>author_org_abrev</th>\n",
       "      <th>section</th>\n",
       "      <th>analysis_head</th>\n",
       "      <th>answer_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mr jean-sébastien vialatte attire l' attention...</td>\n",
       "      <td>PA2907</td>\n",
       "      <td>Les Républicains</td>\n",
       "      <td>LES-REP</td>\n",
       "      <td>santé</td>\n",
       "      <td>remboursement</td>\n",
       "      <td>Affaires sociales et santé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mr hervé pellois attire l' attention de mr le ...</td>\n",
       "      <td>PA607595</td>\n",
       "      <td>Socialiste, républicain et citoyen</td>\n",
       "      <td>SRC</td>\n",
       "      <td>élevage</td>\n",
       "      <td>bovins</td>\n",
       "      <td>Agriculture, agroalimentaire et forêt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mme anne grommerch attire l' attention de mr l...</td>\n",
       "      <td>PA343623</td>\n",
       "      <td>Union pour un Mouvement Populaire</td>\n",
       "      <td>UMP</td>\n",
       "      <td>entreprises</td>\n",
       "      <td>entreprises en difficulté</td>\n",
       "      <td>Travail, emploi, formation professionnelle et ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              q_text author_id  \\\n",
       "0  mr jean-sébastien vialatte attire l' attention...    PA2907   \n",
       "1  mr hervé pellois attire l' attention de mr le ...  PA607595   \n",
       "2  mme anne grommerch attire l' attention de mr l...  PA343623   \n",
       "\n",
       "                           author_org author_org_abrev      section  \\\n",
       "0                    Les Républicains          LES-REP        santé   \n",
       "1  Socialiste, républicain et citoyen              SRC      élevage   \n",
       "2   Union pour un Mouvement Populaire              UMP  entreprises   \n",
       "\n",
       "               analysis_head  \\\n",
       "0              remboursement   \n",
       "1                     bovins   \n",
       "2  entreprises en difficulté   \n",
       "\n",
       "                                          answer_min  \n",
       "0                         Affaires sociales et santé  \n",
       "1              Agriculture, agroalimentaire et forêt  \n",
       "2  Travail, emploi, formation professionnelle et ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save into dataframes\n",
    "df_questions.to_csv(\"data/legislature_XIV/df_questions.csv\", index=False)\n",
    "#df_actors.to_csv(\"data/legislature_XIV/df_actors.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:blue'> XV legislature </span>\n",
    "We repeat the same previous steps for the 15th legislature."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Questions dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions :  45665\n"
     ]
    }
   ],
   "source": [
    "# loading questions\n",
    "PATH_JSON_XV_QUESTIONS = \"data/legislature_XV/questions\"\n",
    "\n",
    "# prepare dictionary of questions for the dataframe\n",
    "info_questions = {'q_text':[], 'author_id':[], 'author_org':[], 'author_org_abrev':[], 'section':[], 'analysis_head':[], 'answer_min':[]}\n",
    "\n",
    "for filename in os.listdir(PATH_JSON_XV_QUESTIONS):\n",
    "    fjson = open(os.path.join(PATH_JSON_XV_QUESTIONS, filename), 'r')\n",
    "    question = json.loads(fjson.read())\n",
    "    try:\n",
    "        q_text = question['question']['textesQuestion']['texteQuestion']['texte']\n",
    "    except:\n",
    "        q_text = question['question']['textesQuestion']['texteQuestion'][0]['texte']\n",
    "    author_id = question['question']['auteur']['identite']['acteurRef']\n",
    "    author_org = question['question']['auteur']['groupe']['developpe']\n",
    "    author_org_abrev = question['question']['auteur']['groupe']['abrege']\n",
    "    section = question['question']['indexationAN']['rubrique']\n",
    "    analysis_head = question['question']['indexationAN']['teteAnalyse']\n",
    "    answer_min = question['question']['minInt']['abrege']\n",
    "\n",
    "    info_questions['q_text'].append(q_text)\n",
    "    info_questions['author_id'].append(author_id)\n",
    "    info_questions['author_org'].append(author_org)\n",
    "    info_questions['author_org_abrev'].append(author_org_abrev)\n",
    "    info_questions['section'].append(section)\n",
    "    info_questions['analysis_head'].append(analysis_head)\n",
    "    info_questions['answer_min'].append(answer_min)\n",
    "\n",
    "    \n",
    "# creating dataframes\n",
    "df_questions = pd.DataFrame(info_questions)\n",
    "\n",
    "print('Number of questions : ', len(df_questions))  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = list(df_questions['q_text'])\n",
    "\n",
    "# remove html tags using BeautifulSoup\n",
    "html_q = preprocess.remove_tags(text_list)\n",
    "\n",
    "# removing some anomalies: \\xa0, apostrophes (replace \\' by '), url\n",
    "cln_corpus = preprocess.remove_anomalies(html_q)\n",
    "\n",
    "# inserting the clean text into the dataframe\n",
    "df_questions['q_text'] = cln_corpus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Actors dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading info actors\n",
    "PATH_JSON_XV_ACTORS = \"data/legislature_XV/info_deputes_senateurs_ministres/acteur\"\n",
    "\n",
    "# prepare dictionary of actors for the dataframe\n",
    "info_actors = {'author_id':[], 'civ':[], 'firstname':[], 'lastname':[], 'birth_date':[], 'birth_dep': [], 'birth_country':[]}\n",
    "\n",
    "for filename in os.listdir(PATH_JSON_XV_ACTORS):\n",
    "    fjson = open(os.path.join(PATH_JSON_XV_ACTORS, filename), 'r')\n",
    "    actor = json.loads(fjson.read())\n",
    "\n",
    "    author_id = actor['acteur']['uid']['#text']\n",
    "    civ = actor['acteur']['etatCivil']['ident']['civ']\n",
    "    firstname = actor['acteur']['etatCivil']['ident']['prenom']\n",
    "    lastname = actor['acteur']['etatCivil']['ident']['nom']\n",
    "    birth_date = actor['acteur']['etatCivil']['infoNaissance']['dateNais']\n",
    "    birth_dep = actor['acteur']['etatCivil']['infoNaissance']['depNais']\n",
    "    birth_country = actor['acteur']['etatCivil']['infoNaissance']['paysNais']\n",
    "    if type(birth_date) != str:\n",
    "        birth_date = None\n",
    "    if type(birth_dep) != str:\n",
    "        birth_dep = None\n",
    "    if type(birth_country) != str:\n",
    "        birth_country = None\n",
    "\n",
    "    info_actors['author_id'].append(author_id)\n",
    "    info_actors['civ'].append(civ)\n",
    "    info_actors['firstname'].append(firstname)\n",
    "    info_actors['lastname'].append(lastname)\n",
    "    info_actors['birth_date'].append(birth_date)\n",
    "    info_actors['birth_dep'].append(birth_dep)\n",
    "    info_actors['birth_country'].append(birth_country)\n",
    "\n",
    "# creating dataframes\n",
    "df_actors = pd.DataFrame(info_actors)\n",
    "\n",
    "# ensure there are no duplicate instances\n",
    "len(df_actors) == df_actors['author_id'].nunique()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Save datasets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save into dataframes\n",
    "df_questions.to_csv(\"data/legislature_XV/df_questions.csv\", index=False)\n",
    "df_actors.to_csv(\"data/legislature_XV/df_actors.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ac4dd57e112d19d14b0fd710bc094b32303c8396eea6a84bec21e9a8576ce75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
