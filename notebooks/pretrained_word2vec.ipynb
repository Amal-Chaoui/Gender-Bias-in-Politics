{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic and grammatical gender exploration in pre-trained word2vec models\n",
    "\n",
    "The word2vec models that will be used in this notebook were pre-trained by [Jean-Philippe Fauconnier](https://fauconnier.github.io/#research)\n",
    " on the French Wikipedia.\n",
    " \n",
    "**Citation:**\n",
    "\n",
    "\t\t@misc{fauconnier_2015,\n",
    "\t\t\tauthor = {Fauconnier, Jean-Philippe},\n",
    "\t\t\ttitle = {French Word Embeddings},\n",
    "\t\t\turl = {http://fauconnier.github.io},\n",
    "\t\t\tyear = {2015}}\t"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "unexpected end of input; is count incorrect or file otherwise damaged?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/amalchaoui/Documents/G4/Research_project/git_code/notebooks/pretrained_word2vec.ipynb Cell 3\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amalchaoui/Documents/G4/Research_project/git_code/notebooks/pretrained_word2vec.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Word2Vec\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amalchaoui/Documents/G4/Research_project/git_code/notebooks/pretrained_word2vec.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#KeyedVectors.load_word2vec_format('../../pretrained_word2vec/frWiki_no_lem_no_postag_no_phrase_1000_cbow_cut200.bin', binary=True)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/amalchaoui/Documents/G4/Research_project/git_code/notebooks/pretrained_word2vec.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m word_vectors \u001b[39m=\u001b[39m KeyedVectors\u001b[39m.\u001b[39;49mload_word2vec_format(\u001b[39m'\u001b[39;49m\u001b[39m../../pretrained_word2vec/frWiki_no_lem_no_postag_no_phrase_1000_cbow_cut200.txt\u001b[39;49m\u001b[39m'\u001b[39;49m, binary\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, unicode_errors\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mignore\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/gensim/models/keyedvectors.py:1629\u001b[0m, in \u001b[0;36mKeyedVectors.load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[1;32m   1582\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m   1583\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_word2vec_format\u001b[39m(\n\u001b[1;32m   1584\u001b[0m         \u001b[39mcls\u001b[39m, fname, fvocab\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, binary\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m'\u001b[39m, unicode_errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1585\u001b[0m         limit\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, datatype\u001b[39m=\u001b[39mREAL, no_header\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1586\u001b[0m     ):\n\u001b[1;32m   1587\u001b[0m     \u001b[39m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[1;32m   1588\u001b[0m \n\u001b[1;32m   1589\u001b[0m \u001b[39m    Warnings\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \n\u001b[1;32m   1628\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1629\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_word2vec_format(\n\u001b[1;32m   1630\u001b[0m         \u001b[39mcls\u001b[39;49m, fname, fvocab\u001b[39m=\u001b[39;49mfvocab, binary\u001b[39m=\u001b[39;49mbinary, encoding\u001b[39m=\u001b[39;49mencoding, unicode_errors\u001b[39m=\u001b[39;49municode_errors,\n\u001b[1;32m   1631\u001b[0m         limit\u001b[39m=\u001b[39;49mlimit, datatype\u001b[39m=\u001b[39;49mdatatype, no_header\u001b[39m=\u001b[39;49mno_header,\n\u001b[1;32m   1632\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/gensim/models/keyedvectors.py:1976\u001b[0m, in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[1;32m   1972\u001b[0m         _word2vec_read_binary(\n\u001b[1;32m   1973\u001b[0m             fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size,\n\u001b[1;32m   1974\u001b[0m         )\n\u001b[1;32m   1975\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1976\u001b[0m         _word2vec_read_text(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding)\n\u001b[1;32m   1977\u001b[0m \u001b[39mif\u001b[39;00m kv\u001b[39m.\u001b[39mvectors\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(kv):\n\u001b[1;32m   1978\u001b[0m     logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m   1979\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mduplicate words detected, shrinking matrix size from \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1980\u001b[0m         kv\u001b[39m.\u001b[39mvectors\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39mlen\u001b[39m(kv),\n\u001b[1;32m   1981\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/gensim/models/keyedvectors.py:1880\u001b[0m, in \u001b[0;36m_word2vec_read_text\u001b[0;34m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding)\u001b[0m\n\u001b[1;32m   1878\u001b[0m line \u001b[39m=\u001b[39m fin\u001b[39m.\u001b[39mreadline()\n\u001b[1;32m   1879\u001b[0m \u001b[39mif\u001b[39;00m line \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m-> 1880\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39munexpected end of input; is count incorrect or file otherwise damaged?\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1881\u001b[0m word, weights \u001b[39m=\u001b[39m _word2vec_line_to_vector(line, datatype, unicode_errors, encoding)\n\u001b[1;32m   1882\u001b[0m _add_word_to_kv(kv, counts, word, weights, vocab_size)\n",
      "\u001b[0;31mEOFError\u001b[0m: unexpected end of input; is count incorrect or file otherwise damaged?"
     ]
    }
   ],
   "source": [
    "from gensim.models import keyedvectors, KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "#KeyedVectors.load_word2vec_format('../../pretrained_word2vec/frWiki_no_lem_no_postag_no_phrase_1000_cbow_cut200.bin', binary=True)\n",
    "word_vectors = KeyedVectors.load_word2vec_format('../../pretrained_word2vec/frWiki_no_lem_no_postag_no_phrase_1000_cbow_cut200.txt', binary=False, unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Word2Vec' has no attribute 'wv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/amalchaoui/Documents/G4/Research_project/git_code/notebooks/pretrained_word2vec.ipynb Cell 4\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/amalchaoui/Documents/G4/Research_project/git_code/notebooks/pretrained_word2vec.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Word2Vec\u001b[39m.\u001b[39;49mwv\u001b[39m.\u001b[39mload_word2vec_format(\u001b[39m'\u001b[39m\u001b[39m../../pretrained_word2vec/frWiki_no_lem_no_postag_no_phrase_1000_cbow_cut200.bin\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'Word2Vec' has no attribute 'wv'"
     ]
    }
   ],
   "source": [
    "Word2Vec.load_word2vec_format('../../pretrained_word2vec/frWiki_no_lem_no_postag_no_phrase_1000_cbow_cut200.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "unexpected end of input; is count incorrect or file otherwise damaged?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/amalchaoui/Documents/G4/Research_project/git_code/notebooks/pretrained_word2vec.ipynb Cell 4\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amalchaoui/Documents/G4/Research_project/git_code/notebooks/pretrained_word2vec.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m embeddings_index \u001b[39m=\u001b[39m {}\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amalchaoui/Documents/G4/Research_project/git_code/notebooks/pretrained_word2vec.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m KeyedVectors\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/amalchaoui/Documents/G4/Research_project/git_code/notebooks/pretrained_word2vec.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m wv_from_bin \u001b[39m=\u001b[39m KeyedVectors\u001b[39m.\u001b[39;49mload_word2vec_format(filepath, binary\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m) \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amalchaoui/Documents/G4/Research_project/git_code/notebooks/pretrained_word2vec.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m word, vector \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(wv_from_bin\u001b[39m.\u001b[39mvocab, wv_from_bin\u001b[39m.\u001b[39mvectors):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amalchaoui/Documents/G4/Research_project/git_code/notebooks/pretrained_word2vec.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     coefs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(vector, dtype\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/gensim/models/keyedvectors.py:1629\u001b[0m, in \u001b[0;36mKeyedVectors.load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[1;32m   1582\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m   1583\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_word2vec_format\u001b[39m(\n\u001b[1;32m   1584\u001b[0m         \u001b[39mcls\u001b[39m, fname, fvocab\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, binary\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m'\u001b[39m, unicode_errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1585\u001b[0m         limit\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, datatype\u001b[39m=\u001b[39mREAL, no_header\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1586\u001b[0m     ):\n\u001b[1;32m   1587\u001b[0m     \u001b[39m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[1;32m   1588\u001b[0m \n\u001b[1;32m   1589\u001b[0m \u001b[39m    Warnings\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \n\u001b[1;32m   1628\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1629\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_word2vec_format(\n\u001b[1;32m   1630\u001b[0m         \u001b[39mcls\u001b[39;49m, fname, fvocab\u001b[39m=\u001b[39;49mfvocab, binary\u001b[39m=\u001b[39;49mbinary, encoding\u001b[39m=\u001b[39;49mencoding, unicode_errors\u001b[39m=\u001b[39;49municode_errors,\n\u001b[1;32m   1631\u001b[0m         limit\u001b[39m=\u001b[39;49mlimit, datatype\u001b[39m=\u001b[39;49mdatatype, no_header\u001b[39m=\u001b[39;49mno_header,\n\u001b[1;32m   1632\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/gensim/models/keyedvectors.py:1972\u001b[0m, in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[1;32m   1969\u001b[0m kv \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(vector_size, vocab_size, dtype\u001b[39m=\u001b[39mdatatype)\n\u001b[1;32m   1971\u001b[0m \u001b[39mif\u001b[39;00m binary:\n\u001b[0;32m-> 1972\u001b[0m     _word2vec_read_binary(\n\u001b[1;32m   1973\u001b[0m         fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size,\n\u001b[1;32m   1974\u001b[0m     )\n\u001b[1;32m   1975\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1976\u001b[0m     _word2vec_read_text(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/gensim/models/keyedvectors.py:1873\u001b[0m, in \u001b[0;36m_word2vec_read_binary\u001b[0;34m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size)\u001b[0m\n\u001b[1;32m   1871\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1872\u001b[0m \u001b[39mif\u001b[39;00m tot_processed_words \u001b[39m!=\u001b[39m vocab_size:\n\u001b[0;32m-> 1873\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39munexpected end of input; is count incorrect or file otherwise damaged?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mEOFError\u001b[0m: unexpected end of input; is count incorrect or file otherwise damaged?"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "filepath = \"../../pretrained_word2vec/frWiki_no_lem_no_postag_no_phrase_1000_cbow_cut200.txt\"\n",
    "\n",
    "embeddings_index = {}\n",
    "from gensim.models import KeyedVectors\n",
    "wv_from_bin = KeyedVectors.load_word2vec_format(filepath, binary=True) \n",
    "for word, vector in zip(wv_from_bin.vocab, wv_from_bin.vectors):\n",
    "    coefs = np.asarray(vector, dtype='float32')\n",
    "    embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ac4dd57e112d19d14b0fd710bc094b32303c8396eea6a84bec21e9a8576ce75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
